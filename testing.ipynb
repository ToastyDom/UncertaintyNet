{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\domenic.bersch\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "[5000. 5000. 5000. 5000. 5000. 5000. 5000. 5000. 5000. 5000.]\n",
      "[5000. 5000. 5000. 4000. 2500. 1000. 1000. 1000.  500.  500.]\n"
     ]
    }
   ],
   "source": [
    "# Which classes do we have\n",
    "classes = list(train_dataset.classes)\n",
    "print(classes)\n",
    "\n",
    "# Count current classes\n",
    "class_counter = np.zeros(len(classes))\n",
    "for data, label in train_dataset:\n",
    "    class_counter[label] +=1\n",
    "\n",
    "print(class_counter)\n",
    "\n",
    "\n",
    "\n",
    "percentage = [1, 1, 1, 0.8, 0.5, 0.2, 0.2, 0.2, 0.1, 0.1]\n",
    "\n",
    "print(class_counter * percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the number of images for each class\n",
    "num_images = [500, 500, 500, 500, 500, 1000, 1000, 1000, 1000, 2000]\n",
    "\n",
    "# Create a list of indices for the total number of images\n",
    "indices = list(range(len(train_dataset)))\n",
    "\n",
    "\"\"\" We want to go through all the data. If the data matches the current class, put it in a \n",
    "tmp list. And then just save a subsection of it to our dataset\"\"\"\n",
    "class_indices = []\n",
    "for i in range(len(classes)):  # i ist jeweils eine Klasse\n",
    "    data_from_this_class = []\n",
    "    for j in range(len(train_dataset)):   # j ist jeweils ein data label paar aus dem Datensatz\n",
    "        if train_dataset[j][1] == i:  # Wenn die aktuelle Klasse mit der Datei übereinstimmt\n",
    "            data_from_this_class.append(indices[j]) # wir wissen dass element j zu dieser Klasse dazu gehört\n",
    "    \n",
    "    class_indices.append(data_from_this_class[:num_images[i]])  # Nimm aber nur so viele wie oben angegeben\n",
    "\n",
    "\n",
    "# Flatten the list\n",
    "class_indices = [item for sublist in class_indices for item in sublist]\n",
    "\n",
    "# Create a new dataset with the new indices\n",
    "imbalanced_dataset = torch.utils.data.Subset(train_dataset, class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transform = T.Compose([T.Resize((224,224)),  #resises the image so it can be perfect for our model.\n",
    "                                T.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
    "                                T.RandomRotation(10),     #Rotates the image to a specified angel\n",
    "                                T.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "                                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "                                T.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "                                T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #Normalize all the images\n",
    "                                ])\n",
    "\n",
    "transform = T.Compose([T.ToTensor(),\n",
    "                        T.Resize((224,224)),\n",
    "                        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset2 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "\n",
    "testset2 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "[ 500.  500.  500.  500.  500. 1000. 1000. 1000. 1000. 2000.]\n"
     ]
    }
   ],
   "source": [
    "# Which classes do we have\n",
    "classes = list(train_dataset.classes)\n",
    "print(classes)\n",
    "\n",
    "# Count current classes\n",
    "class_counter = np.zeros(len(classes))\n",
    "for data, label in imbalanced_dataset:\n",
    "    class_counter[label] +=1\n",
    "\n",
    "print(class_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,9, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[50][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "3\n",
      "tensor([1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'CIFAR10' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mUbuntu-22.04\\home\\domenic\\repositories\\UncertaintyNet\\testing.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-22.04/home/domenic/repositories/UncertaintyNet/testing.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m list_dataset \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(dataset[i])\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-22.04/home/domenic/repositories/UncertaintyNet/testing.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m list_dataset[\u001b[39m1\u001b[39m]\u001b[39m=\u001b[39m changed_element\n\u001b[1;32m---> <a href='vscode-notebook-cell://wsl%24/Ubuntu-22.04/home/domenic/repositories/UncertaintyNet/testing.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m dataset[i] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(list_dataset)\n\u001b[0;32m     <a href='vscode-notebook-cell://wsl%24/Ubuntu-22.04/home/domenic/repositories/UncertaintyNet/testing.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset[i][\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'CIFAR10' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "#accessing CIFAR10 dataset\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "#changing the dataset\n",
    "for i in range(len(dataset)):\n",
    "    if torch.rand(1)<0.1:  # with a probability of 10%\n",
    "        print(dataset[i][1])\n",
    "        changed_element = (dataset[i][1] + torch.randint(1,9, (1,))) % 10\n",
    "        print(changed_element)\n",
    "        list_dataset = list(dataset[i])\n",
    "        list_dataset[1]= changed_element\n",
    "        dataset[i] = tuple(list_dataset)\n",
    "        print(dataset[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add incorrect labels with 10% probability\n",
    "import random\n",
    "for data in dataset:\n",
    "    if random.random() < 0.1:\n",
    "        # Randomly select a label not equal to the correct one\n",
    "        incorrect_label = random.choice([x for x in range(10) if x != data[1]])\n",
    "        data = (data[0], incorrect_label)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3921d23450b9f90f982ef9131efd34b4c85bf39d43193f0dfbded548c24a1b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
