{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "[5000. 5000. 5000. 5000. 5000. 5000. 5000. 5000. 5000. 5000.]\n",
      "[5000. 5000. 5000. 4000. 2500. 1000. 1000. 1000.  500.  500.]\n"
     ]
    }
   ],
   "source": [
    "# Which classes do we have\n",
    "classes = list(train_dataset.classes)\n",
    "print(classes)\n",
    "\n",
    "# Count current classes\n",
    "class_counter = np.zeros(len(classes))\n",
    "for data, label in train_dataset:\n",
    "    class_counter[label] +=1\n",
    "\n",
    "print(class_counter)\n",
    "\n",
    "\n",
    "\n",
    "percentage = [1, 1, 1, 0.8, 0.5, 0.2, 0.2, 0.2, 0.1, 0.1]\n",
    "\n",
    "print(class_counter * percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the number of images for each class\n",
    "num_images = [500, 500, 500, 500, 500, 1000, 1000, 1000, 1000, 2000]\n",
    "\n",
    "# Create a list of indices for the total number of images\n",
    "indices = list(range(len(train_dataset)))\n",
    "\n",
    "\"\"\" We want to go through all the data. If the data matches the current class, put it in a \n",
    "tmp list. And then just save a subsection of it to our dataset\"\"\"\n",
    "class_indices = []\n",
    "for i in range(len(classes)):  # i ist jeweils eine Klasse\n",
    "    data_from_this_class = []\n",
    "    for j in range(len(train_dataset)):   # j ist jeweils ein data label paar aus dem Datensatz\n",
    "        if train_dataset[j][1] == i:  # Wenn die aktuelle Klasse mit der Datei übereinstimmt\n",
    "            data_from_this_class.append(indices[j]) # wir wissen dass element j zu dieser Klasse dazu gehört\n",
    "    \n",
    "    class_indices.append(data_from_this_class[:num_images[i]])  # Nimm aber nur so viele wie oben angegeben\n",
    "\n",
    "\n",
    "# Flatten the list\n",
    "class_indices = [item for sublist in class_indices for item in sublist]\n",
    "\n",
    "# Create a new dataset with the new indices\n",
    "imbalanced_dataset = torch.utils.data.Subset(train_dataset, class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transform = T.Compose([T.Resize((224,224)),  #resises the image so it can be perfect for our model.\n",
    "                                T.RandomHorizontalFlip(), # FLips the image w.r.t horizontal axis\n",
    "                                T.RandomRotation(10),     #Rotates the image to a specified angel\n",
    "                                T.RandomAffine(0, shear=10, scale=(0.8,1.2)), #Performs actions like zooms, change shear angles.\n",
    "                                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Set the color params\n",
    "                                T.ToTensor(), # comvert the image to tensor so that it can work with torch\n",
    "                                T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) #Normalize all the images\n",
    "                                ])\n",
    "\n",
    "transform = T.Compose([T.ToTensor(),\n",
    "                        T.Resize((224,224)),\n",
    "                        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset2 = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
    "\n",
    "\n",
    "testset2 = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainset2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "[ 500.  500.  500.  500.  500. 1000. 1000. 1000. 1000. 2000.]\n"
     ]
    }
   ],
   "source": [
    "# Which classes do we have\n",
    "classes = list(train_dataset.classes)\n",
    "print(classes)\n",
    "\n",
    "# Count current classes\n",
    "class_counter = np.zeros(len(classes))\n",
    "for data, label in imbalanced_dataset:\n",
    "    class_counter[label] +=1\n",
    "\n",
    "print(class_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(1,9, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[50][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accessing CIFAR10 dataset\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "#changing the dataset\n",
    "for i in range(len(dataset)):\n",
    "    if torch.rand(1)<0.1:  # with a probability of 10%\n",
    "        dataset[i][1] = (dataset[i][1] + torch.randint(1,9, (1,))) % 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3921d23450b9f90f982ef9131efd34b4c85bf39d43193f0dfbded548c24a1b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
